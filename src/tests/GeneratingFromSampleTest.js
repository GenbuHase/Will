const fs = require("fs");
const fsEx = require("fs-extra");
const Mastodon = require("mastodon-api");

const Initializer = require("./../libs/Initializer");
const Logger = require("./../libs/Logger");
const Generator = require("./../libs/Generator");



/** @type {Initializer.ShiinaEnv} */
const ENV = process.env;

const mstdn = new Mastodon({ api_url: `${ENV.SHIINA_INSTANCE}/api/v1/`, access_token: ENV.SHIINA_TOKEN });
const generator = new Generator();

const sampleRootDir = `${ENV.SHIINA_HOMEDIR}/samples`;
const readingQues = [];

for (const type of ["both", "vocabulary", "structure"]) {
	const dir = `${sampleRootDir}/${type}`;
	if (!fs.existsSync(dir)) fsEx.mkdirsSync(dir);
	
	const files = fs.readdirSync(dir);

	const ques = [];
	for (const file of files) {
		const parseQue = fsEx.readJSON(`${dir}/${file}`);
		parseQue.then(() => console.info(`${file} had been loaded`));

		ques.push(parseQue);
	}

	readingQues.push(
		Promise.all(ques).then(databases => {
			for (const db of databases) {
				switch (type) {
					default:
						break;
					case "both":
						generator.importDatabase(db);
						break;
					case "vocabulary":
						for (const tokenized of db) generator.dictionary.vocabularies.register(tokenized);
						break;
					case "structure":
						for (const tokenized of db) generator.dictionary.structures.register(tokenized);
						break;
				}
			}

			return;
		})
	);
}

Promise.all(readingQues).then(() => {
	const tootingQues = [];

	//Generating sentences
	for (let i = 0; i < 10; i++) {
		const status = generator.generate("");

		console.info("== Generated by Shiina ==");
		console.log(status);

		if (!ENV.DOES_TOOT) continue;

		tootingQues.push(
			mstdn.post("statuses", {
				status,
				spoiler_text: "== Generated by Shiina ==",
				
				visibility: "unlisted"
			})
		);
	}

	return Promise.all(tootingQues);
}).then(() => process.kill(process.pid));